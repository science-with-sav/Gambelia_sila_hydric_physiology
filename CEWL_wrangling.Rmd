---
title: "BNLL CEWL Data Wrangling"
author: "Savannah Weaver"
output: pdf_document
toc: TRUE
---


# Packages

```{r setup, include=FALSE}
`%nin%` = Negate(`%in%`)
if (!require("tidyverse")) install.packages("tidyverse")
library("tidyverse") # workflow and plots
```


# Background and Goals

This CEWL (cutaneous evaporative water loss) data was collected ...


Please refer to **doi:** for the published scientific journal article and full details.


# Load Data

1. Compile a list of the filenames I need to read-in.

```{r}
# make a list of file names of all data to load in
filenames <- list.files(path = "data/CEWL")
```

2. Make a function that will read in the data from each csv, name and organize the data correctly. 

```{r}
read_CEWL_file <- function(filename) {
  
  dat <- read.csv(file.path("data/CEWL", filename),
                  na.strings=c("","NA"),
                # each csv has headers
                header = TRUE
                ) %>%
    # select only the relevant values
    dplyr::select(date = Date, 
                  time = Time, 
                  status = Status,
                  ID_rep_no = Comments,
                  CEWL_g_m2h = 'TEWL..g..m2h..', 
                  msmt_temp_C = 'AmbT..C.', 
                  msmt_RH_percent = 'AmbRH....'
                  ) %>%
    # extract individual_ID and replicate number
    dplyr::mutate(ID_rep_no = as.character(ID_rep_no),
                  ID_len = as.factor(nchar(ID_rep_no)),
                  
                  individual_ID = as.factor(case_when(
                    ID_len == 7 ~ as.character(paste(substr(ID_rep_no, 1, 1),
                                             substr(ID_rep_no, 3, 5),
                                             sep = "")),
                    ID_len == 6 & substr(ID_rep_no, 1, 1) == "W" 
                        ~ as.character(substr(ID_rep_no, 1, 4)),
                    ID_len == 6 & substr(ID_rep_no, 1, 1) %in% c("M", "F") 
                        ~ as.character(paste(substr(ID_rep_no, 1, 1),
                                             substr(ID_rep_no, 3, 4),
                                             sep = "")),
                    ID_len == 5 ~ as.character(substr(ID_rep_no, 1, 3))
                    )),
                  
                  # works
                  replicate_no = as.factor(case_when(
                    ID_len == 7 ~ as.character(substr(ID_rep_no, 7, 7)),
                    ID_len == 6 ~ as.character(substr(ID_rep_no, 6, 6)),
                    ID_len == 5 ~ as.character(substr(ID_rep_no, 5, 5))
                    )))
  
  # return the dataframe for that single csv file
  dat
}
```

3. Apply the function I made to all of the filenames I compiled, then put all of those dataframes into one dataframe. This will print warnings saying that header and col.names are different lengths, because the data has extra notes cols that we read-in, but get rid of. Additionally, filter out failed measurements and properly format data classes.

```{r}
# apply function to get data from all csvs
all_CEWL_data <- lapply(filenames, read_CEWL_file) %>%
  # paste all data files together into one df by row
  reduce(rbind) %>%
  # filter out failed measurements
  dplyr::filter(status == "Normal") %>%
  # correctly format data classes
  mutate(date = as.Date(date, format = "%m/%d/%y"),
         time = as.POSIXct(time, format = "%H:%M"),
         status = as.factor(status)
         )

summary(all_CEWL_data)
```




# Check Data

Each lizard measured on each date should have 3-5 technical replicates, and those measurements should have been taken around the same time. 

```{r}
all_CEWL_data %>%
                group_by(individual_ID, date) %>%
                summarise(n = n(),
                          time_range = max(time) - min(time)) %>% 
                arrange(n)
```

The number of measurements taken is good! Almost always 3 or 5, with two lizards who only got 4 measurements, which is fine. But, M01 on April 23 and M03a on July 14 have abnormal time ranges of 43140 seconds (almost 12h), so we need to check that data.

```{r}
all_CEWL_data %>% dplyr::filter(individual_ID %in% c("M01", "M03A"))
```

Aha, it seems the problem is that the time isn't perfectly formatted, so 1 pm is coded as 1 am --> the measurements in question went across hours of 12 noon to 1 pm, so when reformatted, it seems like 1 am to 12 pm. It's fine as-is, and nothing is amiss with the data.





# Replicates

## Assess Variation

We want the Coefficient of Variation (CV) among our technical replicates to be small. We need to calculate it to identify whether there may be outliers.

```{r asses variation}
CVs <- all_CEWL_data %>%
  group_by(individual_ID, date) %>%
  summarise(mean = mean(CEWL_g_m2h),
            SD = sd(CEWL_g_m2h),
            CV = (SD/mean) *100,
            min = min(CEWL_g_m2h),
            max = max(CEWL_g_m2h),
            range = max - min
            )
summary(CVs)
hist(CVs$CV)
hist(CVs$range) 
```

We expect CV for technical replicates to be < 10-15%, so we must determine whether the CVs > 15% are due to outlier replicates.


## Find Outliers

First, create a function to look at the replicates for each individual on each day. For each iteration, I will make a boxplot and extract any outliers, compiling a dataframe of outliers that I want to exclude from the final dataset. By printing the boxplots and compiling a dataframe of outliers, I can check the data against the plots to ensure confidence in the outliers quantified.

```{r function to find outliers}
# write function to find outliers for each individual on each date
find_outliers <- function(df) {
  
  # initiate dataframe to compile info and list to compile plots
  outliers <- data.frame()
  #boxplots <- list()

  # initiate a for loop to go through every who in df
  for(indiv_ch in unique(df$individual_ID)) {
    
    # select data for only the individual of interest
    df_sub <- df %>%
      dplyr::filter(individual_ID == (indiv_ch))
    
    # make a boxplot
    df_sub %>%
      ggplot(.) +
      geom_boxplot(aes(x = as.factor(date),
                       y = CEWL_g_m2h,
                       fill = as.factor(date))) +
      ggtitle(paste("Individual", indiv_ch)) +
      theme_classic() -> plot
    
    # print/save
    print(plot)
    #boxplots[[indiv_ch]] <- plot
    
    # extract outliers
    outs <- df_sub %>%
      group_by(individual_ID, date) %>%
      summarise(outs = boxplot.stats(CEWL_g_m2h)$out)
    
    # add to running dataframe of outliers
    outliers <- outliers %>%
      rbind(outs)
  }
  #return(boxplots)
  return(outliers)
}
```


Now apply the function to the data:

```{r show outliers, fig.show = "hold", out.width = "50%"}
par(mfrow = c(71, 2))
outliers_found <- find_outliers(all_CEWL_data)
outliers_found
par(mfrow = c(1, 1))
```

Based on the plots, the dataframe of outliers I compiled is correct. (yay!)


## Remove Outliers

Now I will create a secondary version of the same function, but instead of compiling outliers, I will omit them from the dataset.

```{r function to remove outliers}
# write function to find and exclude outliers
omit_outliers <- function(df) {
  
  # initiate dataframe to compile info and list to compile plots
  cleaned <- data.frame()

  # initiate a for loop to go through every who in df
  for(indiv_ch in unique(df$individual_ID)) {
    
    # select data for only the individual of interest
    df_sub <- df %>%
      dplyr::filter(individual_ID == (indiv_ch))
    
    # extract outliers
    outs <- df_sub %>%
      group_by(individual_ID, date) %>%
      summarise(outs = boxplot.stats(CEWL_g_m2h)$out)
    
    # filter outliers from data subset for this individual
    filtered <- df_sub %>%
      dplyr::filter(CEWL_g_m2h %nin% outs$outs)
    
    # add to running dataframe of cleaned data
    cleaned <- cleaned %>%
      rbind(filtered)
  }
  return(cleaned)
}
```


Apply function to data and check that the new data subsets still contain the right amount of data:

```{r omit outliers, message = FALSE}
outliers_omitted <- omit_outliers(all_CEWL_data)
nrow(all_CEWL_data) == nrow(outliers_omitted) + nrow(outliers_found)
```




## Re-Assess Variation

```{r re-check variation}
new_CVs <- outliers_omitted %>%
  group_by(individual_ID, date) %>%
  summarise(mean = mean(CEWL_g_m2h),
            SD = sd(CEWL_g_m2h),
            CV = (SD/mean) *100,
            min = min(CEWL_g_m2h),
            max = max(CEWL_g_m2h),
            range = max - min)
summary(new_CVs)
hist(new_CVs$CV)
hist(CVs$CV)
hist(new_CVs$range) 
hist(CVs$range) 
```


Unfortunately, CVs are still skewed to the right, but many CVs were improved. We will continue with this dataset.


## Average Replicates (outliers removed)

```{r get replicate means}
CEWL_final <- outliers_omitted %>%
  group_by(date, individual_ID) %>%
  summarise(CEWL_g_m2h = mean(CEWL_g_m2h),
            msmt_temp_C = mean(msmt_temp_C),
            msmt_RH_percent = mean(msmt_RH_percent))
head(CEWL_final)
```


# Final Synthesis

## Re-Check Data

Check that we still have data for every individual.

I can check this by comparing a list of the individual IDs used (201-341) to the individual IDs in our final dataset, then selecting/printing the IDs used that are not in the final dataset.

```{r re-check individual IDs}
unique(CEWL_final$individual_ID) %in% unique(all_CEWL_data$individual_ID)
unique(all_CEWL_data$individual_ID) %in% unique(CEWL_final$individual_ID)
```

All is as expected. :)

Check how many observations were used to calculate mean CEWL for each individual on each date:

```{r re-check n obs}
outliers_omitted %>%
  group_by(individual_ID, date) %>%
  summarise(n = n()) %>% 
  arrange(n)
```


Between 3-5, awesome! That means we omitted 2 or less replicates for each individual on each measurement date. 


## Export

Save the cleaned data for models and figures.

```{r save clean data}
write.csv(CEWL_final, "./data/CEWL_dat_all_clean.csv")
```





## Reporting

We omitted a total of 24 measurements from our CEWL dataset. We used the boxplot.stats function in R to extract outliers from each set of technical replicates, totaling 24 points qualifying as outliers which were thus removed. After data cleaning, every individual still had 3-5 technical replicates for each of their measurement dates. The distribution of coefficient of variation values was slightly better after data cleaning than before. For the individuals who only had 3 replicates taken, they probably didn't have enough reps for outliers to be found and omitted, so that's probably what made CVs stay high. 


