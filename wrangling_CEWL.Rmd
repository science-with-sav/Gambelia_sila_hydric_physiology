---
title: "BNLL CEWL Data Wrangling"
author: "Savannah Weaver"
output: 
  rmarkdown::html_vignette:
    highlight: tango
    thumbnails: FALSE
    toc: TRUE
    toc_depth: 3
---


# Packages

```{r setup, include=FALSE}
`%nin%` = Negate(`%in%`)
if (!require("tidyverse")) install.packages("tidyverse")
library("tidyverse") # workflow and plots
if (!require("rmdformats")) install.packages("rmdformats")
library("rmdformats") # clean html R markdown format
```


# Background and Goals

This CEWL (cutaneous evaporative water loss) data was measured in 3-5 technical replicates on the mid-dorsum of Blunt-nosed Leopard Lizards (*Gambelia sila*) between April - July 2021. In this R script, I check the distribution of replicates, omit outliers, and average remaining replicates. The final values will be more precise and accurate estimates of the true CEWL for each lizard, and those values will be used in the analyses R script file. Please refer to **doi:** for the published scientific paper and full details.



# Load Data

1. Compile a list of the filenames I need to read-in.

```{r}
# make a list of file names of all data to load in
filenames <- list.files(path = "data/CEWL")
```

2. Make a function that will read in the data from each csv, name and organize the data correctly. 

```{r}
read_CEWL_file <- function(filename) {
  
  dat <- read.csv(file.path("data/CEWL", filename),
                  na.strings=c("","NA"),
                # each csv has headers
                header = TRUE
                ) %>%
    # select only the relevant values
    dplyr::select(date = Date, 
                  time = Time, 
                  status = Status,
                  ID_rep_no = Comments,
                  CEWL_g_m2h = 'TEWL..g..m2h..', 
                  msmt_temp_C = 'AmbT..C.', 
                  msmt_RH_percent = 'AmbRH....'
                  ) 
  
  # return the dataframe for that single csv file
  dat
}
```

3. Apply the function I made to all of the filenames I compiled, then put all of those dataframes into one dataframe. This will print warnings saying that header and col.names are different lengths, because the data has extra notes cols that we read-in, but get rid of. Additionally, filter out failed measurements and properly format data classes.

```{r}
# apply function to get data from all csvs
all_CEWL_data <- lapply(filenames, read_CEWL_file) %>%
  # paste all data files together into one df by row
  reduce(rbind) %>%
    # extract individual_ID and replicate number
    dplyr::mutate(ID_rep_no = as.character(ID_rep_no),
                  ID_len = as.factor(nchar(ID_rep_no)),
                  
                  individual_ID = as.factor(case_when(
                    ID_len == 7 ~ as.character(paste(substr(ID_rep_no, 1, 1),
                                             substr(ID_rep_no, 3, 5),
                                             sep = "-")),
                    ID_len == 6 & substr(ID_rep_no, 1, 1) == "W" 
                        ~ as.character(paste(substr(ID_rep_no, 1, 1),
                                             substr(ID_rep_no, 2, 4),
                                             sep = "-")),
                    ID_len == 6 & substr(ID_rep_no, 1, 1) %in% c("M", "F") 
                        ~ as.character(paste(substr(ID_rep_no, 1, 1),
                                             substr(ID_rep_no, 3, 4),
                                             sep = "-")),
                    ID_len == 5 ~ as.character(paste(substr(ID_rep_no, 1, 1),
                                             substr(ID_rep_no, 2, 3),
                                             sep = "-")))
                    ),
                  replicate_no = as.factor(case_when(
                    ID_len == 7 ~ as.character(substr(ID_rep_no, 7, 7)),
                    ID_len == 6 ~ as.character(substr(ID_rep_no, 6, 6)),
                    ID_len == 5 ~ as.character(substr(ID_rep_no, 5, 5))
                    ))) %>%
  # filter out failed measurements
  dplyr::filter(status == "Normal") %>%
  # correctly format data classes
  mutate(date = as.Date(date, format = "%m/%d/%y"),
         time = as.POSIXct(time, format = "%H:%M"),
         status = as.factor(status)
         )

summary(all_CEWL_data)
unique(all_CEWL_data$individual_ID)
```




# Check Data

Each lizard measured on each date should have 3-5 technical replicates, and those measurements should have been taken around the same time. 

```{r}
all_CEWL_data %>%
                group_by(individual_ID, date) %>%
                summarise(n = n(),
                          time_range = max(time) - min(time)) %>% 
                arrange(n)
```

The number of measurements taken is good! Almost always 3 or 5, with two lizards who only got 4 measurements, which is fine. But, M01 on April 23 and M03a on July 14 have abnormal time ranges of 43140 seconds (almost 12h), so we need to check that data.

```{r}
all_CEWL_data %>% dplyr::filter(individual_ID %in% c("M-01", "M-03A"))
```

Aha, it seems the problem is that the time isn't perfectly formatted, so 1 pm is coded as 1 am --> the measurements in question went across hours of 12 noon to 1 pm, so when reformatted, it seems like 1 am to 12 pm. It's fine as-is, and nothing is amiss with the data.





# Replicates

## Assess Variation

We want the Coefficient of Variation (CV) among our technical replicates to be small. We need to calculate it to identify whether there may be outliers.

```{r asses variation}
CVs <- all_CEWL_data %>%
  group_by(individual_ID, date) %>%
  summarise(mean = mean(CEWL_g_m2h),
            SD = sd(CEWL_g_m2h),
            CV = (SD/mean) *100,
            min = min(CEWL_g_m2h),
            max = max(CEWL_g_m2h),
            range = max - min
            )
summary(CVs)
hist(CVs$CV)
hist(CVs$range) 
```

We expect CV for technical replicates to be < 10-15%, so we must determine whether the CVs > 15% are due to outlier replicates. The range should also generally be within 5 units for these measurements. :(


## Find Outliers

First, create a function to look at the replicates for each individual on each day. For each iteration, I will make a boxplot and extract any outliers, compiling a dataframe of outliers that I want to exclude from the final dataset. By printing the boxplots and compiling a dataframe of outliers, I can check the data against the plots to ensure confidence in the outliers quantified.

```{r function to find outliers}
# write function to find outliers for each individual on each date
find_outliers <- function(df) {
  
  # initiate dataframe to compile info and list to compile plots
  outliers <- data.frame()
  #boxplots <- list()

  # initiate a for loop to go through every who in df
  for(indiv_ch in unique(df$individual_ID)) {
    
    # select data for only the individual of interest
    df_sub <- df %>%
      dplyr::filter(individual_ID == (indiv_ch))
    
    # make a boxplot
    df_sub %>%
      ggplot(.) +
      geom_boxplot(aes(x = as.factor(date),
                       y = CEWL_g_m2h,
                       fill = as.factor(date))) +
      ggtitle(paste("Individual", indiv_ch)) +
      theme_classic() -> plot
    
    # print/save
    print(plot)
    #boxplots[[indiv_ch]] <- plot
    
    # extract outliers
    outs <- df_sub %>%
      group_by(individual_ID, date) %>%
      summarise(outs = boxplot.stats(CEWL_g_m2h)$out)
    
    # add to running dataframe of outliers
    outliers <- outliers %>%
      rbind(outs)
  }
  #return(boxplots)
  return(outliers)
}
```


Now apply the function to the data:

```{r show outliers, fig.show = "hold", out.width = "50%"}
par(mfrow = c(71, 2))
outliers_found <- find_outliers(all_CEWL_data)
outliers_found
par(mfrow = c(1, 1))
```

Based on the plots, the dataframe of outliers I compiled is correct. (yay!)


## Remove Outliers

Now I will create a secondary version of the same function, but instead of compiling outliers, I will omit them from the dataset.

```{r function to remove outliers}
# write function to find and exclude outliers
omit_outliers <- function(df) {
  
  # initiate dataframe to compile info and list to compile plots
  cleaned <- data.frame()

  # initiate a for loop to go through every who in df
  for(indiv_ch in unique(df$individual_ID)) {
    
    # select data for only the individual of interest
    df_sub <- df %>%
      dplyr::filter(individual_ID == (indiv_ch))
    
    # extract outliers
    outs <- df_sub %>%
      group_by(individual_ID, date) %>%
      summarise(outs = boxplot.stats(CEWL_g_m2h)$out)
    
    # filter outliers from data subset for this individual
    filtered <- df_sub %>%
      dplyr::filter(CEWL_g_m2h %nin% outs$outs)
    
    # add to running dataframe of cleaned data
    cleaned <- cleaned %>%
      rbind(filtered)
  }
  return(cleaned)
}
```


Apply function to data and check that the new data subsets still contain the right amount of data:

```{r omit outliers, message = FALSE}
outliers_omitted <- omit_outliers(all_CEWL_data)
nrow(all_CEWL_data) == nrow(outliers_omitted) + nrow(outliers_found)
```




## Re-Assess Variation

```{r re-check variation}
new_CVs <- outliers_omitted %>%
  group_by(individual_ID, date) %>%
  summarise(mean = mean(CEWL_g_m2h),
            SD = sd(CEWL_g_m2h),
            CV = (SD/mean) *100,
            min = min(CEWL_g_m2h),
            max = max(CEWL_g_m2h),
            range = max - min)
summary(new_CVs)
hist(new_CVs$CV)
hist(CVs$CV)
hist(new_CVs$range) 
hist(CVs$range) 
```


This definitely improved things, but unfortunately, CVs are still skewed to the right. I think the replicate groups with only 3 replicates are harder to find outliers in.

Check the info for lizards with super high value ranges:

```{r}
new_CVs %>%
  dplyr::filter(range > 10)
```

Look at the original CEWL measurements for those lizards: 

```{r}
outliers_omitted %>%
  dplyr::filter(individual_ID == "F-02" & date == "2021-04-23")
outliers_omitted %>%
  dplyr::filter(individual_ID == "F-05" & date == "2021-04-24")
outliers_omitted %>%
  dplyr::filter(individual_ID == "F-06" & date == "2021-04-24")
outliers_omitted %>%
  dplyr::filter(individual_ID == "F-11" & date == "2021-05-08") # fine
outliers_omitted %>%
  dplyr::filter(individual_ID == "F-14" & date == "2021-04-24")
outliers_omitted %>%
  dplyr::filter(individual_ID == "F-17" & date == "2021-05-08") # fine
outliers_omitted %>%
  dplyr::filter(individual_ID == "M-10" & date == "2021-04-24")
outliers_omitted %>%
  dplyr::filter(individual_ID == "W-013" & date == "2021-04-24")
outliers_omitted %>%
  dplyr::filter(individual_ID == "W-016" & date == "2021-04-24") # fine
outliers_omitted %>%
  dplyr::filter(individual_ID == "W-017" & date == "2021-04-24")
outliers_omitted %>%
  dplyr::filter(individual_ID == "W-024" & date == "2021-04-24") # fine
outliers_omitted %>%
  dplyr::filter(individual_ID == "W-026" & date == "2021-04-25")
outliers_omitted %>%
  dplyr::filter(individual_ID == "W-031" & date == "2021-05-07") # def need to remove negative value, yikes
outliers_omitted %>%
  dplyr::filter(individual_ID == "W-037" & date == "2021-05-08")
```



## Remove Extreme Values

```{r}
evs_omitted <- outliers_omitted %>%
  dplyr::filter(!(individual_ID == "F-02" & CEWL_g_m2h == 26.69)) %>%
  dplyr::filter(!(individual_ID == "F-05" & CEWL_g_m2h == 65.31)) %>%
  dplyr::filter(!(individual_ID == "F-06" & CEWL_g_m2h == 28.92)) %>%
  dplyr::filter(!(individual_ID == "F-14" & CEWL_g_m2h == 26.25)) %>%
  dplyr::filter(!(individual_ID == "M-10" & CEWL_g_m2h == 30.79)) %>%
  dplyr::filter(!(individual_ID == "W-013" & CEWL_g_m2h == 23.36)) %>%
  dplyr::filter(!(individual_ID == "W-017" & CEWL_g_m2h == 24.31)) %>%
  dplyr::filter(!(individual_ID == "W-026" & CEWL_g_m2h == 42.56)) %>%
  dplyr::filter(!(individual_ID == "W-031" & CEWL_g_m2h == -1.32)) %>%
  dplyr::filter(!(individual_ID == "W-037" & CEWL_g_m2h == 7.48))
nrow(outliers_omitted) == nrow(evs_omitted) + 10
```

## Re-Assess Variation

```{r re-check variation 2}
new_new_CVs <- evs_omitted %>%
  group_by(individual_ID, date) %>%
  summarise(mean = mean(CEWL_g_m2h),
            SD = sd(CEWL_g_m2h),
            CV = (SD/mean) *100,
            min = min(CEWL_g_m2h),
            max = max(CEWL_g_m2h),
            range = max - min)
summary(new_new_CVs)
hist(new_CVs$CV)
hist(new_new_CVs$CV)
hist(new_CVs$range) 
hist(new_new_CVs$range) 
```

Another big improvement. :)

## Average Replicates (outliers removed)

```{r get replicate means}
CEWL_avgs <- evs_omitted %>%
  group_by(date, individual_ID) %>%
  summarise(CEWL_g_m2h_mean = mean(CEWL_g_m2h),
            CEWL_SD = sd(CEWL_g_m2h),
            CEWL_CV = (CEWL_SD/CEWL_g_m2h_mean)*100,
            msmt_temp_C = mean(msmt_temp_C),
            msmt_RH_percent = mean(msmt_RH_percent)) 

# tech rep stats
mean(CEWL_avgs$CEWL_CV)

CEWL_final <- CEWL_avgs %>%
  dplyr::select(date, individual_ID,
                CEWL_g_m2h = CEWL_g_m2h_mean,
                msmt_temp_C, msmt_RH_percent) %>% 
  # calculate VPD based on Campbell & Norman 1998
  mutate(e_s_kPa = 0.611 * exp((17.502*msmt_temp_C)/(msmt_temp_C + 240.97)),
         msmt_VPD_kPa = e_s_kPa*(1 - (msmt_RH_percent/100))
         )
head(CEWL_final)
```


# Final Synthesis

## Re-Check Data

Check that we still have data for every individual.

I can check this by comparing original individual IDs to the individual IDs in our final dataset, then selecting/printing the IDs used that are in one but not the other.

```{r re-check individual IDs}
unique(CEWL_final$individual_ID) %in% unique(all_CEWL_data$individual_ID)
unique(all_CEWL_data$individual_ID) %in% unique(CEWL_final$individual_ID)
```

All is as expected. :)

Check how many observations were used to calculate mean CEWL for each individual on each date:

```{r re-check n obs}
evs_omitted %>%
  group_by(individual_ID, date) %>%
  summarise(n = n()) %>% 
  arrange(n)
```


Between 2-5.



## Export

Save the cleaned data for models and figures.

```{r save clean data}
write_rds(CEWL_final, "./data/CEWL_dat_all_clean.RDS")
```





## Reporting

We omitted a total of 105 measurements from our CEWL dataset (465 - 351): 1 replicate was removed for most individuals. We used the boxplot.stats function in R to extract outliers from each set of technical replicates, and 24 points were removed this way (outliers_found dataframe). We removed an additional 10 extreme replicate values from rep groups with extremely high CEWL value ranges where the rest of the reps were very similar; this was always for rep sets of 3, so the outlier just couldn't be detected statistically. After data cleaning, every individual still had 2-5 technical replicates for each of their measurement dates. The distribution of coefficient of variation values was much better after both data cleaning steps than before.


